{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-05-16T16:07:10.644234Z",
     "iopub.status.busy": "2025-05-16T16:07:10.643875Z",
     "iopub.status.idle": "2025-05-16T16:07:12.509121Z",
     "shell.execute_reply": "2025-05-16T16:07:12.508243Z",
     "shell.execute_reply.started": "2025-05-16T16:07:10.644205Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-16T16:07:12.510999Z",
     "iopub.status.busy": "2025-05-16T16:07:12.510514Z",
     "iopub.status.idle": "2025-05-16T16:07:29.180758Z",
     "shell.execute_reply": "2025-05-16T16:07:29.179171Z",
     "shell.execute_reply.started": "2025-05-16T16:07:12.510967Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_35/1564683150.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mitem_features_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"item_categories.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0minteractions_big_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minteractions_big_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0minteractions_small_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minteractions_small_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mitem_features_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem_features_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 626\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1921\u001b[0m                     \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1922\u001b[0m                     \u001b[0mcol_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m                 \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1924\u001b[0m                     \u001b[0mnrows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1925\u001b[0m                 )\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m                 \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_low_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m                 \u001b[0;31m# destructive to chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_concatenate_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'."
     ]
    }
   ],
   "source": [
    "base_path = \"/kaggle/input/kuairec-content-based\"\n",
    "interactions_big_path = os.path.join(base_path, \"big_matrix.csv\")\n",
    "interactions_small_path = os.path.join(base_path, \"small_matrix.csv\")\n",
    "item_features_path = os.path.join(base_path, \"item_categories.csv\")\n",
    "\n",
    "interactions_big_df = pd.read_csv(interactions_big_path)\n",
    "interactions_small_df = pd.read_csv(interactions_small_path)\n",
    "item_features_df = pd.read_csv(item_features_path)\n",
    "\n",
    "print(f\"Interactions shape: {interactions_big_df.shape}\")\n",
    "print(f\"Interactions small shape: {interactions_small_df.shape}\")\n",
    "print(f\"Item features shape: {item_features_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-05-16T16:07:29.181390Z",
     "iopub.status.idle": "2025-05-16T16:07:29.181687Z",
     "shell.execute_reply": "2025-05-16T16:07:29.181571Z",
     "shell.execute_reply.started": "2025-05-16T16:07:29.181559Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "interactions_big_df.drop(columns=[\"date\", 'time'], inplace=True)\n",
    "interactions_big_df.rename(columns={'user_id': 'userId', 'video_id': 'itemId'}, inplace=True)\n",
    "interactions_small_df.drop(columns=[\"date\", 'time'], inplace=True)\n",
    "interactions_small_df.rename(columns={'user_id': 'userId', 'video_id': 'itemId'}, inplace=True)\n",
    "\n",
    "item_features_df[\"feat\"] = item_features_df[\"feat\"].map(eval)\n",
    "all_categories = [i for i in range(31)]\n",
    "\n",
    "items_preproccesed = pd.DataFrame(index=item_features_df.index)\n",
    "\n",
    "for category in sorted(all_categories):\n",
    "    column_name = category\n",
    "    items_preproccesed[column_name] = item_features_df['feat'].apply(lambda x: 1 if category in x else 0)\n",
    "items_preproccesed['video_id'] = item_features_df[\"video_id\"]\n",
    "items_preproccesed.drop(columns=[14, 23, 27, 21, 0, 30, 22, 24, 29], inplace=True)\n",
    "items_preproccesed.rename(columns={'video_id':'itemId'}, inplace=True)\n",
    "\n",
    "items_preproccesed.set_index('itemId', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-05-16T16:07:29.185407Z",
     "iopub.status.idle": "2025-05-16T16:07:29.185682Z",
     "shell.execute_reply": "2025-05-16T16:07:29.185572Z",
     "shell.execute_reply.started": "2025-05-16T16:07:29.185560Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.merge(interactions_big_df, items_preproccesed, on='itemId', how='left')\n",
    "test_data = pd.merge(interactions_small_df, items_preproccesed, on='itemId', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-05-16T16:07:29.186864Z",
     "iopub.status.idle": "2025-05-16T16:07:29.187112Z",
     "shell.execute_reply": "2025-05-16T16:07:29.187010Z",
     "shell.execute_reply.started": "2025-05-16T16:07:29.187000Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_data = train_data[train_data['watch_ratio'] <= 5]\n",
    "test_data = test_data[test_data['watch_ratio'] <= 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-05-16T16:07:29.187994Z",
     "iopub.status.idle": "2025-05-16T16:07:29.188263Z",
     "shell.execute_reply": "2025-05-16T16:07:29.188129Z",
     "shell.execute_reply.started": "2025-05-16T16:07:29.188119Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class LearningToRankRecommender:\n",
    "    def __init__(self, item_features_df, params=None):\n",
    "        self.item_features_df = item_features_df\n",
    "        self.model = None\n",
    "        self.user_profiles = {}\n",
    "        \n",
    "        self.params = {\n",
    "            'objective': 'rank:ndcg',\n",
    "            'learning_rate': 0.05,\n",
    "            'max_depth': 6,\n",
    "            'subsample': 0.8,\n",
    "            'colsample_bytree': 0.8,\n",
    "            'min_child_weight': 1,\n",
    "            'gamma': 0.1,\n",
    "            'tree_method': 'hist',\n",
    "            'n_estimators': 200\n",
    "        }\n",
    "        \n",
    "        if params:\n",
    "            self.params.update(params)\n",
    "            \n",
    "    def fit(self, train_data, feature_cols=None):\n",
    "        \"\"\"Train an XGBoost ranking model for personalized recommendations.\"\"\"\n",
    "        \n",
    "        if feature_cols is None:\n",
    "            feature_cols = train_data.select_dtypes(include=['int64', 'float64', 'bool']).columns.tolist()\n",
    "            feature_cols = [col for col in feature_cols if col not in ['userId', 'itemId', 'watch_ratio']]\n",
    "        \n",
    "        print(f\"Using features: {feature_cols}\")\n",
    "        \n",
    "        train_data_copy = train_data.copy()\n",
    "        \n",
    "        print(\"Converting watch_ratio to discrete relevance levels...\")\n",
    "        \n",
    "        bins = [0, 1, 2, 3, 4, 5]\n",
    "        labels = [0, 1, 2, 3, 4]\n",
    "        \n",
    "        train_data_copy['relevance'] = pd.cut(\n",
    "            train_data_copy['watch_ratio'], \n",
    "            bins=bins, \n",
    "            labels=labels, \n",
    "            include_lowest=True\n",
    "        ).astype(int)\n",
    "        \n",
    "        print(\"Training XGBRanker model...\")\n",
    "        X = train_data_copy[feature_cols].values\n",
    "        y = train_data_copy['relevance'].values\n",
    "        \n",
    "        train_data_copy['user_idx'] = train_data_copy['userId'].astype('category').cat.codes\n",
    "        \n",
    "        groups = train_data_copy.groupby('user_idx').size().values\n",
    "        \n",
    "        self.model = xgb.XGBRanker(\n",
    "            objective=self.params['objective'],\n",
    "            learning_rate=self.params['learning_rate'],\n",
    "            max_depth=self.params['max_depth'],\n",
    "            subsample=self.params['subsample'],\n",
    "            colsample_bytree=self.params['colsample_bytree'],\n",
    "            min_child_weight=self.params['min_child_weight'],\n",
    "            gamma=self.params['gamma'],\n",
    "            tree_method=self.params['tree_method'],\n",
    "            n_estimators=self.params['n_estimators']\n",
    "        )\n",
    "        \n",
    "        print(f\"Training with {len(groups)} user groups...\")\n",
    "        self.model.fit(X, y, group=groups, verbose=True)\n",
    "        \n",
    "        print(\"Creating user profiles...\")\n",
    "        for user_id, group in train_data.groupby('userId'):\n",
    "            self.user_profiles[user_id] = group[feature_cols].mean().values\n",
    "            \n",
    "        return self\n",
    "\n",
    "\n",
    "    \n",
    "    def predict(self, test_data, feature_cols=None):\n",
    "        \"\"\"Generate ranking scores for test data.\"\"\"\n",
    "        if feature_cols is None:\n",
    "            feature_cols = self.item_features_df.columns.tolist()\n",
    "            feature_cols = [col for col in feature_cols if col not in ['userId', 'itemId', 'watch_ratio']]\n",
    "            \n",
    "        X_test = test_data[feature_cols].values\n",
    "        \n",
    "        predictions = self.model.predict(X_test)\n",
    "        return predictions\n",
    "        \n",
    "    def evaluate(self, test_data, feature_cols=None, k=10, relevance_threshold=0.8):\n",
    "        \"\"\"Evaluate the ranking model using multiple metrics.\"\"\"\n",
    "        if feature_cols is None:\n",
    "            feature_cols = test_data.columns.tolist()\n",
    "            feature_cols = [col for col in feature_cols if col not in ['userId', 'itemId', 'watch_ratio']]\n",
    "        \n",
    "        print(\"Generating predictions for evaluation...\")\n",
    "        X_test = test_data[feature_cols].values\n",
    "        y_true = test_data['watch_ratio'].values\n",
    "        \n",
    "        test_data['prediction'] = self.model.predict(X_test)\n",
    "        \n",
    "        rmse = np.sqrt(mean_squared_error(y_true, test_data['prediction']))\n",
    "        mae = np.mean(np.abs(y_true - test_data['prediction']))\n",
    "        \n",
    "        print(f\"\\nCalculating ranking metrics at k={k}...\")\n",
    "        \n",
    "        precision = self._calculate_precision(test_data, k=k)\n",
    "        \n",
    "        hit_rate = self._calculate_hit_rate(test_data, k=k, relevance_threshold=relevance_threshold)\n",
    "        \n",
    "        mrr = self._calculate_mrr(test_data, k=k, relevance_threshold=relevance_threshold)\n",
    "        \n",
    "        ndcg = self._calculate_ndcg(test_data, k=k)\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.scatter(y_true, test_data['prediction'], alpha=0.3)\n",
    "        plt.plot([0, 5], [0, 5], 'r--')\n",
    "        plt.xlabel('Actual Watch Ratio')\n",
    "        plt.ylabel('Predicted Ranking Score')\n",
    "        plt.title('Actual vs Predicted Ranking Score')\n",
    "        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"RMSE: {rmse:.4f}\")\n",
    "        print(f\"MAE: {mae:.4f}\")\n",
    "        print(f\"Precision@{k}: {precision:.4f}\")\n",
    "        print(f\"Hit Rate@{k}: {hit_rate:.4f}\")\n",
    "        print(f\"MRR@{k}: {mrr:.4f}\")\n",
    "        print(f\"NDCG@{k}: {ndcg:.4f}\")\n",
    "        \n",
    "        return {\n",
    "            \"rmse\": rmse,\n",
    "            \"mae\": mae,\n",
    "            \"precision\": precision,\n",
    "            \"hit_rate\": hit_rate,\n",
    "            \"mrr\": mrr,\n",
    "            \"ndcg\": ndcg\n",
    "        }\n",
    "    \n",
    "    def _calculate_precision(self, test_data, k=10):\n",
    "        \"\"\"Calculate Precision@k.\"\"\"\n",
    "        top_k_preds = (\n",
    "            test_data.groupby('userId')\n",
    "            .apply(lambda x: x.nlargest(k, 'prediction'))\n",
    "            .reset_index(drop=True)\n",
    "        )\n",
    "        \n",
    "        top_k_actual = (\n",
    "            test_data.groupby('userId')\n",
    "            .apply(lambda x: x.nlargest(k, 'watch_ratio'))\n",
    "            .reset_index(drop=True)\n",
    "        )\n",
    "        \n",
    "        joined_items = pd.merge(\n",
    "            top_k_preds[['userId', 'itemId']],\n",
    "            top_k_actual[['userId', 'itemId']],\n",
    "            on=['userId', 'itemId'],\n",
    "            how='inner'\n",
    "        )\n",
    "        \n",
    "        precision = len(joined_items) / len(top_k_preds) if len(top_k_preds) > 0 else 0\n",
    "        return precision\n",
    "\n",
    "    def _calculate_hit_rate(self, test_data, k=10, relevance_threshold=0.8):\n",
    "        \"\"\"Calculate Hit Rate@k.\"\"\"\n",
    "        top_k_preds = (\n",
    "            test_data.groupby('userId')\n",
    "            .apply(lambda x: x.nlargest(k, 'prediction'))\n",
    "            .reset_index(drop=True)[['userId', 'itemId']]\n",
    "        )\n",
    "        \n",
    "        relevant_items = test_data[test_data['watch_ratio'] >= relevance_threshold][['userId', 'itemId']]\n",
    "        \n",
    "        users_with_relevant_items = relevant_items['userId'].unique()\n",
    "        num_users_with_relevant_items = len(users_with_relevant_items)\n",
    "        \n",
    "        if num_users_with_relevant_items == 0:\n",
    "            return 0.0\n",
    "        \n",
    "        hits = pd.merge(\n",
    "            top_k_preds,\n",
    "            relevant_items,\n",
    "            on=['userId', 'itemId'],\n",
    "            how='inner'\n",
    "        )\n",
    "        \n",
    "        users_with_hits = hits['userId'].unique()\n",
    "        users_with_hits_count = len(users_with_hits)\n",
    "        \n",
    "        hit_rate = users_with_hits_count / num_users_with_relevant_items\n",
    "        return hit_rate\n",
    "\n",
    "    def _calculate_mrr(self, test_data, k=10, relevance_threshold=0.8):\n",
    "        \"\"\"Calculate MRR@k.\"\"\"\n",
    "        ranked_preds = []\n",
    "        for user_id, group in test_data.groupby('userId'):\n",
    "            sorted_group = group.sort_values('prediction', ascending=False).head(k)\n",
    "            sorted_group['rank'] = range(1, len(sorted_group) + 1)\n",
    "            ranked_preds.append(sorted_group)\n",
    "        \n",
    "        if len(ranked_preds) == 0:\n",
    "            return 0.0\n",
    "        \n",
    "        ranked_preds_df = pd.concat(ranked_preds, ignore_index=True)\n",
    "        \n",
    "        relevant_items = test_data[test_data['watch_ratio'] >= relevance_threshold][['userId', 'itemId']]\n",
    "        \n",
    "        users_with_relevant_items = relevant_items['userId'].unique()\n",
    "        num_users_with_relevant_items = len(users_with_relevant_items)\n",
    "        \n",
    "        if num_users_with_relevant_items == 0:\n",
    "            return 0.0\n",
    "        \n",
    "        hits_with_rank = pd.merge(\n",
    "            ranked_preds_df[['userId', 'itemId', 'rank']],\n",
    "            relevant_items,\n",
    "            on=['userId', 'itemId'],\n",
    "            how='inner'\n",
    "        )\n",
    "        \n",
    "        if len(hits_with_rank) > 0:\n",
    "            first_hit_per_user = hits_with_rank.groupby('userId')['rank'].min().reset_index()\n",
    "            first_hit_per_user['reciprocal_rank'] = 1 / first_hit_per_user['rank']\n",
    "            total_rr = first_hit_per_user['reciprocal_rank'].sum()\n",
    "        else:\n",
    "            total_rr = 0\n",
    "        \n",
    "        mrr = total_rr / num_users_with_relevant_items\n",
    "        return mrr\n",
    "    \n",
    "    def _calculate_ndcg(self, test_data, k=10):\n",
    "        \"\"\"Calculate NDCG@k (Normalized Discounted Cumulative Gain).\"\"\"\n",
    "        ndcg_scores = []\n",
    "        \n",
    "        for user_id, group in test_data.groupby('userId'):\n",
    "            user_preds = group.sort_values('prediction', ascending=False).head(k)\n",
    "            \n",
    "            if len(user_preds) == 0:\n",
    "                continue\n",
    "                \n",
    "            relevance_scores = user_preds['watch_ratio'].values\n",
    "            \n",
    "            dcg = relevance_scores[0]\n",
    "            for i in range(1, len(relevance_scores)):\n",
    "                dcg += relevance_scores[i] / np.log2(i + 1 + 1)\n",
    "                \n",
    "            ideal_relevance = np.sort(group['watch_ratio'].values)[::-1][:k]\n",
    "            idcg = ideal_relevance[0]\n",
    "            for i in range(1, len(ideal_relevance)):\n",
    "                idcg += ideal_relevance[i] / np.log2(i + 1 + 1)\n",
    "                \n",
    "            ndcg = dcg / idcg if idcg > 0 else 0\n",
    "            ndcg_scores.append(ndcg)\n",
    "            \n",
    "        return np.mean(ndcg_scores) if ndcg_scores else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-05-16T16:07:29.189375Z",
     "iopub.status.idle": "2025-05-16T16:07:29.189682Z",
     "shell.execute_reply": "2025-05-16T16:07:29.189555Z",
     "shell.execute_reply.started": "2025-05-16T16:07:29.189538Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_data.drop(columns=['timestamp'], inplace=True)\n",
    "#train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-05-16T16:07:29.191082Z",
     "iopub.status.idle": "2025-05-16T16:07:29.191451Z",
     "shell.execute_reply": "2025-05-16T16:07:29.191293Z",
     "shell.execute_reply.started": "2025-05-16T16:07:29.191276Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "ltr_recommender = LearningToRankRecommender(item_features_df)\n",
    "ltr_recommender.fit(train_data, feature_cols=items_preproccesed.columns.tolist())\n",
    "\n",
    "ltr_metrics = ltr_recommender.evaluate(\n",
    "    test_data, \n",
    "    feature_cols=items_preproccesed.columns.tolist(),\n",
    "    k=20,                   \n",
    "    relevance_threshold=0.8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-05-16T16:07:29.192777Z",
     "iopub.status.idle": "2025-05-16T16:07:29.193049Z",
     "shell.execute_reply": "2025-05-16T16:07:29.192947Z",
     "shell.execute_reply.started": "2025-05-16T16:07:29.192936Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "xgb.plot_importance(ltr_recommender.model, max_num_features=15)\n",
    "plt.title('Feature Importance')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 7401694,
     "sourceId": 11788201,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
