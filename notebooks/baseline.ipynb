{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac92d6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyspark.sql import SparkSession, Window\n",
    "from pyspark.sql.functions import col, isnan, when, lit, expr, explode, row_number, sum, udf, min, coalesce, array_contains\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.sql.types import ArrayType, IntegerType, StringType\n",
    "import ast\n",
    "\n",
    "def load_data(spark, train_path, test_path, items_df, users_df):\n",
    "    print(\"Loading training dataset...\")\n",
    "    training_df = spark.read.csv(train_path, header=True, inferSchema=True)\n",
    "    print(\"Loading items dataset...\")\n",
    "    items_df = spark.read.csv(items_df, header=True, inferSchema=True)\n",
    "    print(\"Loading users dataset...\")\n",
    "    users_df = spark.read.csv(users_df, header=True, inferSchema=True)\n",
    "    # Join items and users with training data\n",
    "    training_df = training_df.join(items_df, on=\"video_id\", how=\"left\")\n",
    "    training_df = training_df.join(users_df, on=\"user_id\", how=\"left\")\n",
    "    print(\"Loading test dataset...\")\n",
    "    test_df = spark.read.csv(test_path, header=True, inferSchema=True)\n",
    "    return training_df, test_df\n",
    "\n",
    "def parse_string_to_list(s):\n",
    "    if s is None:\n",
    "        return None\n",
    "    try:\n",
    "        return ast.literal_eval(s)\n",
    "    except (ValueError, SyntaxError):\n",
    "        return None\n",
    "\n",
    "parse_string_to_list_udf = udf(parse_string_to_list, ArrayType(IntegerType()))\n",
    "\n",
    "def clean_data(df):\n",
    "    print(\"Starting data cleaning...\")\n",
    "\n",
    "    # Original watch_ratio cleaning\n",
    "    df = df.filter(col(\"watch_ratio\").isNotNull())\n",
    "    df = df.filter(col(\"watch_ratio\") >= 0)\n",
    "    df = df.filter(~isnan(col(\"watch_ratio\")))\n",
    "    df = df.withColumn(\"capped_watch_ratio\", when(col(\"watch_ratio\") > 5, 5).otherwise(col(\"watch_ratio\")))\n",
    "\n",
    "    interaction_cols_to_drop = []\n",
    "    if \"date\" in df.columns:\n",
    "        interaction_cols_to_drop.append(\"date\")\n",
    "    if \"time\" in df.columns:\n",
    "        interaction_cols_to_drop.append(\"time\")\n",
    "    if interaction_cols_to_drop:\n",
    "        df = df.drop(*interaction_cols_to_drop)\n",
    "        print(f\"Dropped interaction columns: {interaction_cols_to_drop}\")\n",
    "    if \"feat\" in df.columns:\n",
    "        print(\"Processing item features...\")\n",
    "        df = df.withColumn(\"feat_parsed\", parse_string_to_list_udf(col(\"feat\")))\n",
    "\n",
    "        all_categories = list(range(31))\n",
    "        item_cols_to_drop_categories = [14, 23, 27, 21, 0, 30, 22, 24, 29]\n",
    "        \n",
    "        generated_category_cols = []\n",
    "        for category in sorted(all_categories):\n",
    "            cat_col_name = f\"item_category_{category}\"\n",
    "            df = df.withColumn(cat_col_name, \n",
    "                               when(array_contains(col(\"feat_parsed\"), category), 1).otherwise(0))\n",
    "            generated_category_cols.append(cat_col_name)\n",
    "\n",
    "        item_cat_cols_to_actually_drop = [f\"item_category_{i}\" for i in item_cols_to_drop_categories]\n",
    "        item_cat_cols_to_actually_drop = [c for c in item_cat_cols_to_actually_drop if c in df.columns]\n",
    "\n",
    "        df = df.drop(*item_cat_cols_to_actually_drop)\n",
    "        print(f\"Dropped item category columns: {item_cat_cols_to_actually_drop}\")\n",
    "        df = df.drop(\"feat\", \"feat_parsed\")\n",
    "        print(\"Dropped 'feat' and 'feat_parsed' columns.\")\n",
    "    else:\n",
    "        print(\"Columns are:\")\n",
    "        print(df.columns)\n",
    "        print(\"Warning: 'feat' column not found. Skipping item feature preprocessing.\")\n",
    "\n",
    "    if \"user_active_degree\" in df.columns:\n",
    "        print(\"Processing user features...\")\n",
    "        user_cols_to_drop_initial = [\n",
    "            'onehot_feat5', 'onehot_feat15', 'onehot_feat16', 'onehot_feat17',\n",
    "            'is_lowactive_period', 'is_live_streamer', 'follow_user_num_range',\n",
    "            'fans_user_num_range', 'register_days_range', 'friend_user_num_range'\n",
    "        ]\n",
    "        actual_user_cols_to_drop_initial = [c for c in user_cols_to_drop_initial if c in df.columns]\n",
    "        if actual_user_cols_to_drop_initial:\n",
    "            df = df.drop(*actual_user_cols_to_drop_initial)\n",
    "            print(f\"Dropped user feature columns: {actual_user_cols_to_drop_initial}\")\n",
    "\n",
    "        potential_degree_values = []\n",
    "        if \"user_active_degree\" in df.columns:\n",
    "\n",
    "            active_degree_categories = [\"high_active\", \"middle_active\", \"low_active\", \"UNKNOWN\"] # Example list\n",
    "            for cat_val in active_degree_categories:\n",
    "                if cat_val in df.columns: # If it was already a column somehow\n",
    "                    print(f\"Warning: Column {cat_val} for active degree already exists. Skipping creation.\")\n",
    "                    continue\n",
    "                df = df.withColumn(cat_val, when(col(\"user_active_degree\") == cat_val, 1).otherwise(0))\n",
    "            \n",
    "            df = df.drop(\"user_active_degree\")\n",
    "            print(\"Dropped 'user_active_degree' column.\")\n",
    "\n",
    "            user_cols_to_drop_dummies = []\n",
    "            if \"UNKNOWN\" in df.columns:\n",
    "                 user_cols_to_drop_dummies.append(\"UNKNOWN\")\n",
    "            if \"middle_active\" in df.columns: \n",
    "                 user_cols_to_drop_dummies.append(\"middle_active\")\n",
    "            \n",
    "            if user_cols_to_drop_dummies:\n",
    "                df = df.drop(*user_cols_to_drop_dummies)\n",
    "                print(f\"Dropped user active degree dummy columns: {user_cols_to_drop_dummies}\")\n",
    "    else:\n",
    "        print(\"Warning: 'user_active_degree' column not found. Skipping user feature preprocessing related to active degree.\")\n",
    "\n",
    "    if \"capped_watch_ratio\" not in df.columns:\n",
    "        print(\"Error: 'capped_watch_ratio' is not available for engagement score calculation. Setting engagement_score to 0.\")\n",
    "        df = df.withColumn(\"engagement_score\", lit(0.0))\n",
    "        return df\n",
    "\n",
    "    engagement_score_expr = col(\"capped_watch_ratio\") * lit(1.0)\n",
    "\n",
    "    interaction_signals = [\n",
    "        (\"is_like\", 1.5),\n",
    "        (\"is_comment\", 2.0),\n",
    "        (\"is_share\", 2.5)\n",
    "    ]\n",
    "\n",
    "    for signal_col_name, weight in interaction_signals:\n",
    "        if signal_col_name in df.columns:\n",
    "            df = df.withColumn(signal_col_name, coalesce(col(signal_col_name).cast(\"integer\"), lit(0)))\n",
    "            engagement_score_expr = engagement_score_expr + (col(signal_col_name) * lit(weight))\n",
    "        else:\n",
    "            print(f\"Warning: Column '{signal_col_name}' not found. It will not be included in the engagement score.\")\n",
    "\n",
    "    df = df.withColumn(\"engagement_score\", engagement_score_expr)\n",
    "    print(\"Calculated 'engagement_score'.\")\n",
    "    print(\"Data cleaning finished.\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def index_data(training_df, test_df):\n",
    "    print(\"Using existing numerical user_id and video_id columns for ALS...\")\n",
    "    training = training_df.withColumnRenamed(\"user_id\", \"userIndex\").withColumnRenamed(\"video_id\", \"videoIndex\")\n",
    "    test = test_df.withColumnRenamed(\"user_id\", \"userIndex\").withColumnRenamed(\"video_id\", \"videoIndex\")\n",
    "    return training, test\n",
    "\n",
    "def evaluate_als_precision(test_df, predictions,  k=10, rating_col=\"engagement_score\", user_col=\"userIndex\", item_col=\"videoIndex\"):\n",
    "    \n",
    "    predictions = predictions.withColumn(\"rank\", row_number().over(Window.partitionBy(user_col).orderBy(col(\"prediction\").desc())))\n",
    "    predictions = predictions.filter(col(\"rank\") <= k)\n",
    "    predictions = predictions.select(user_col, item_col, \"prediction\")\n",
    "    test_df = test_df.withColumn(\"rank\", row_number().over(Window.partitionBy(user_col).orderBy(col(rating_col).desc())))\n",
    "    test_df = test_df.filter(col(\"rank\") <= k)\n",
    "    test_df = test_df.select(user_col, item_col, rating_col)\n",
    "    joined_df = predictions.join(test_df, on=[user_col, item_col], how=\"inner\")\n",
    "    precision = joined_df.count() / predictions.count()\n",
    "    print(f\"Precision at {k}: {precision:.4f}\")\n",
    "\n",
    "def evaluate_als_hit_rate(test_df, predictions, k=10, user_col=\"userIndex\", item_col=\"videoIndex\", rating_col=\"engagement_score\"):\n",
    "    if \"prediction\" not in predictions.columns:\n",
    "        print(f\"Error in evaluate_als_hit_rate: 'prediction' col not found in predictions. Aborting metric calculation.\")\n",
    "        return 0.0\n",
    "\n",
    "    print(f\"Calculating HitRate@{k}. Relevant items in test set are any (user,item) pairs present.\")\n",
    "\n",
    "    user_window = Window.partitionBy(user_col).orderBy(col(\"prediction\").desc())\n",
    "    top_k_preds = predictions.withColumn(\"rank\", row_number().over(user_window)) \\\n",
    "        .filter(col(\"rank\") <= k) \\\n",
    "        .select(user_col, item_col)\n",
    "\n",
    "    # Filter test_df for relevant items (e.g., items with watch_ratio >= 0.8)\n",
    "    # This defines what a \"relevant\" item is for the ground truth\n",
    "    relevant_test_items = test_df.filter(col(rating_col) >= 0.8) \\\n",
    "        .select(user_col, item_col)\n",
    "\n",
    "    # Identify the set of users who have at least one relevant item in the test set\n",
    "    # These are the users for whom a \"hit\" is possible\n",
    "    users_with_relevant_items_in_test = relevant_test_items.select(user_col).distinct()\n",
    "    num_users_with_relevant_items = users_with_relevant_items_in_test.count()\n",
    "\n",
    "    if num_users_with_relevant_items == 0:\n",
    "        print(f\"Hit Rate at {k}: 0.0000 (No users with relevant items (e.g., {rating_col} >= 0.8) in the test set)\")\n",
    "        return\n",
    "\n",
    "    # Find hits: (user, item) pairs that were recommended in top-K AND are relevant\n",
    "    hits_df = top_k_preds.join(relevant_test_items, on=[user_col, item_col], how=\"inner\")\n",
    "\n",
    "    # Count the number of unique users who had at least one hit\n",
    "    users_with_hits_count = hits_df.select(user_col).distinct().count()\n",
    "\n",
    "    # Calculate Hit Rate\n",
    "    hit_rate = users_with_hits_count / num_users_with_relevant_items\n",
    "    print(f\"Hit Rate at {k}: {hit_rate:.4f}\")\n",
    "\n",
    "def evaluate_als_mrr(test_df, predictions, k=10, user_col=\"userIndex\", item_col=\"videoIndex\", rating_col=\"engagement_score\"):\n",
    "    if \"prediction\" not in predictions.columns:\n",
    "        print(f\"Error in evaluate_als_mrr: 'prediction' col not found in predictions. Aborting metric calculation.\")\n",
    "        return 0.0\n",
    "\n",
    "    print(f\"Calculating MRR@{k}. Relevant items in test set are any (user,item) pairs present.\")\n",
    "\n",
    "    user_window = Window.partitionBy(user_col).orderBy(col(\"prediction\").desc())\n",
    "    ranked_predictions = predictions.withColumn(\"rank\", row_number().over(user_window))\n",
    "\n",
    "    top_k_ranked_predictions = ranked_predictions.filter(col(\"rank\") <= k) \\\n",
    "        .select(user_col, item_col, \"rank\")\n",
    "\n",
    "    # Define relevant items as any (user, item) pair in the test set.\n",
    "    relevant_test_items = test_df.select(user_col, item_col).distinct()\n",
    "\n",
    "    # Users for whom MRR is calculated are those present with items in the test set.\n",
    "\n",
    "    users_for_mrr_denominator_df = relevant_test_items.select(user_col).distinct()\n",
    "    num_users_for_mrr_denominator = users_for_mrr_denominator_df.count()\n",
    "\n",
    "    if num_users_for_mrr_denominator == 0:\n",
    "        print(f\"MRR at {k}: 0.0000 (No users with items in the test set)\")\n",
    "        return 0.0\n",
    "\n",
    "    hits_with_rank_df = top_k_ranked_predictions.join(\n",
    "        relevant_test_items,\n",
    "        on=[user_col, item_col],\n",
    "        how=\"inner\"\n",
    "    ) \n",
    "    first_hit_rank_per_user_df = hits_with_rank_df.groupBy(user_col) \\\n",
    "        .agg(min(\"rank\").alias(\"min_rank_of_hit\"))\n",
    "    \n",
    "    reciprocal_ranks_df = first_hit_rank_per_user_df \\\n",
    "        .withColumn(\"reciprocal_rank\", 1.0 / col(\"min_rank_of_hit\"))\n",
    "    \n",
    "    sum_of_reciprocal_ranks_result = reciprocal_ranks_df.agg(\n",
    "        coalesce(sum(\"reciprocal_rank\"), lit(0.0)).alias(\"total_reciprocal_rank\")\n",
    "    ).first()\n",
    "\n",
    "    total_sum_of_reciprocal_ranks = 0.0\n",
    "    if sum_of_reciprocal_ranks_result:\n",
    "        total_sum_of_reciprocal_ranks = sum_of_reciprocal_ranks_result[\"total_reciprocal_rank\"]\n",
    "\n",
    "    mrr = total_sum_of_reciprocal_ranks / num_users_for_mrr_denominator if num_users_for_mrr_denominator > 0 else 0.0\n",
    "    print(f\"MRR at {k}: {mrr:.4f}\")\n",
    "    return mrr\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73f1c5d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/17 11:46:50 WARN Utils: Your hostname, debian-lenovo resolves to a loopback address: 127.0.1.1; using 192.168.0.18 instead (on interface wlp3s0)\n",
      "25/05/17 11:46:50 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/05/17 11:46:50 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading items dataset...\n",
      "Loading users dataset...\n",
      "Loading test dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting data cleaning...\n",
      "Dropped interaction columns: ['date', 'time']\n",
      "Processing item features...\n",
      "Dropped item category columns: ['item_category_14', 'item_category_23', 'item_category_27', 'item_category_21', 'item_category_0', 'item_category_30', 'item_category_22', 'item_category_24', 'item_category_29']\n",
      "Dropped 'feat' and 'feat_parsed' columns.\n",
      "Processing user features...\n",
      "Dropped user feature columns: ['onehot_feat5', 'onehot_feat15', 'onehot_feat16', 'onehot_feat17', 'is_lowactive_period', 'is_live_streamer', 'follow_user_num_range', 'fans_user_num_range', 'register_days_range', 'friend_user_num_range']\n",
      "Dropped 'user_active_degree' column.\n",
      "Dropped user active degree dummy columns: ['UNKNOWN', 'middle_active']\n",
      "Warning: Column 'is_like' not found. It will not be included in the engagement score.\n",
      "Warning: Column 'is_comment' not found. It will not be included in the engagement score.\n",
      "Warning: Column 'is_share' not found. It will not be included in the engagement score.\n",
      "Calculated 'engagement_score'.\n",
      "Data cleaning finished.\n",
      "Starting data cleaning...\n",
      "Dropped interaction columns: ['date', 'time']\n",
      "Columns are:\n",
      "['user_id', 'video_id', 'play_duration', 'video_duration', 'timestamp', 'watch_ratio', 'capped_watch_ratio']\n",
      "Warning: 'feat' column not found. Skipping item feature preprocessing.\n",
      "Warning: 'user_active_degree' column not found. Skipping user feature preprocessing related to active degree.\n",
      "Warning: Column 'is_like' not found. It will not be included in the engagement score.\n",
      "Warning: Column 'is_comment' not found. It will not be included in the engagement score.\n",
      "Warning: Column 'is_share' not found. It will not be included in the engagement score.\n",
      "Calculated 'engagement_score'.\n",
      "Data cleaning finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset count after cleaning: 12530806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset count after cleaning: 4676570\n",
      "Sample of training data with engagement_score (showing relevant columns):\n",
      "+-------+--------+------------------+------------------+------------------+\n",
      "|user_id|video_id|watch_ratio       |capped_watch_ratio|engagement_score  |\n",
      "+-------+--------+------------------+------------------+------------------+\n",
      "|0      |3649    |1.2733965215790926|1.2733965215790926|1.2733965215790926|\n",
      "|0      |9598    |1.2440823015294975|1.2440823015294975|1.2440823015294975|\n",
      "|0      |5262    |0.1076125442589782|0.1076125442589782|0.1076125442589782|\n",
      "|0      |1963    |0.0898852971845672|0.0898852971845672|0.0898852971845672|\n",
      "|0      |8234    |0.078             |0.078             |0.078             |\n",
      "+-------+--------+------------------+------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Using existing numerical user_id and video_id columns for ALS...\n",
      "Configuring ALS model with 'engagement_score' as rating column...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/17 11:47:54 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.VectorBLAS\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "\n",
    "spark = SparkSession.builder \\\n",
    ".appName(\"KuaiRec_ALS_Engagement_Score_Model\") \\\n",
    ".master(\"local[*]\") \\\n",
    ".config(\"spark.driver.memory\", \"8g\") \\\n",
    ".config(\"spark.sql.adaptive.enabled\", \"true\") \\\n",
    ".config(\"spark.sql.adaptive.coalescePartitions.enabled\", \"true\") \\\n",
    ".getOrCreate()\n",
    "base_path = \"../data_final_project/KuaiRec 2.0/data/\"\n",
    "train_path = base_path + \"big_matrix.csv\"\n",
    "test_path = base_path + \"small_matrix.csv\"\n",
    "items_path = base_path + \"item_categories.csv\"\n",
    "users_path = base_path + \"user_features.csv\"\n",
    "\n",
    "training_df, test_df = load_data(spark, train_path, test_path, items_path, users_path)\n",
    "\n",
    "training_df = clean_data(training_df)\n",
    "test_df = clean_data(test_df)\n",
    "\n",
    "if \"engagement_score\" not in training_df.columns:\n",
    "    print(\"Error: 'engagement_score' column not found after clean_data. Exiting.\")\n",
    "\n",
    "if \"engagement_score\" not in test_df.columns:\n",
    "    print(\"Error: 'engagement_score' column not found in test_df after clean_data. Exiting.\")\n",
    "print(f\"Training dataset count after cleaning: {training_df.count()}\")\n",
    "print(f\"Test dataset count after cleaning: {test_df.count()}\")\n",
    "    \n",
    "print(\"Sample of training data with engagement_score (showing relevant columns):\")\n",
    "\n",
    "final_cols_to_show = []\n",
    "potential_cols = [\"user_id\", \"video_id\", \"watch_ratio\", \"capped_watch_ratio\", \"engagement_score\"]\n",
    "\n",
    "for c in potential_cols:\n",
    "    if c in training_df.columns:\n",
    "        final_cols_to_show.append(c)\n",
    "\n",
    "if final_cols_to_show:\n",
    "    training_df.select(final_cols_to_show).show(5, truncate=False)\n",
    "else:\n",
    "    print(\"No columns selected for showing sample training data, or training_df is empty.\")\n",
    "\n",
    "training, test = index_data(training_df, test_df)\n",
    "\n",
    "print(\"Configuring ALS model with 'engagement_score' as rating column...\")\n",
    "als = ALS(\n",
    "    maxIter=15,\n",
    "    regParam=0.1,\n",
    "    rank=10,\n",
    "    userCol=\"userIndex\",\n",
    "    itemCol=\"videoIndex\",\n",
    "    ratingCol=\"engagement_score\",\n",
    "    coldStartStrategy=\"drop\",\n",
    "    nonnegative=True\n",
    ")\n",
    "\n",
    "model = als.fit(training)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3bdbdb1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions count: 4676570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of predictions (showing relevant columns):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision at 100: 0.3218\n",
      "Calculating HitRate@100. Relevant items in test set are any (user,item) pairs present.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit Rate at 100: 1.0000\n",
      "Calculating MRR@100. Relevant items in test set are any (user,item) pairs present.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2403:=================================================>      (7 + 1) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR at 100: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Generating predictions...\")\n",
    "\n",
    "predictions = model.transform(test) \n",
    "    \n",
    "print(f\"Predictions count: {predictions.count()}\")\n",
    "if predictions.count() == 0:\n",
    "    print(\"Warning: No valid predictions generated. Check your data and ALS parameters.\")\n",
    "\n",
    "if \"prediction\" not in predictions.columns:\n",
    "    print(\"Error: 'prediction' column not found in model output. Schema:\")\n",
    "    predictions.printSchema()\n",
    "    \n",
    "print(\"Sample of predictions (showing relevant columns):\")\n",
    "k_eval = 100 # Top-K for ranking metrics\n",
    "\n",
    "evaluate_als_precision(test, predictions, k=k_eval, user_col=\"userIndex\", item_col=\"videoIndex\")\n",
    "#evaluate_als_recall(test, predictions, k_eval, user_col=\"userIndex\", item_col=\"videoIndex\")\n",
    "evaluate_als_hit_rate(test, predictions, k_eval, user_col=\"userIndex\", item_col=\"videoIndex\")\n",
    "evaluate_als_mrr(test, predictions, k_eval, user_col=\"userIndex\", item_col=\"videoIndex\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6eb453d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
