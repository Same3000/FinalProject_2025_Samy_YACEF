{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf4448d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc4bc539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interactions shape: (12530806, 8)\n",
      "Interactions small shape: (4676570, 8)\n",
      "Item features shape: (10728, 2)\n"
     ]
    }
   ],
   "source": [
    "# Define paths to data files\n",
    "base_path = \"../data_final_project/KuaiRec 2.0/data\"\n",
    "interactions_big_path = os.path.join(base_path, \"big_matrix.csv\")\n",
    "interactions_small_path = os.path.join(base_path, \"small_matrix.csv\")\n",
    "item_features_path = os.path.join(base_path, \"item_categories.csv\")\n",
    "\n",
    "interactions_big_df = pd.read_csv(interactions_big_path)\n",
    "interactions_small_df = pd.read_csv(interactions_small_path)\n",
    "item_features_df = pd.read_csv(item_features_path)\n",
    "\n",
    "print(f\"Interactions shape: {interactions_big_df.shape}\")\n",
    "print(f\"Interactions small shape: {interactions_small_df.shape}\")\n",
    "print(f\"Item features shape: {item_features_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61104e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_big_df.drop(columns=[\"date\", 'time'], inplace=True)\n",
    "interactions_big_df.rename(columns={'user_id': 'userId', 'video_id': 'itemId'}, inplace=True)\n",
    "interactions_small_df.drop(columns=[\"date\", 'time'], inplace=True)\n",
    "interactions_small_df.rename(columns={'user_id': 'userId', 'video_id': 'itemId'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2990b66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_features_df[\"feat\"] = item_features_df[\"feat\"].map(eval)\n",
    "all_categories = [i for i in range(31)]\n",
    "\n",
    "items_preproccesed = pd.DataFrame(index=item_features_df.index)\n",
    "\n",
    "for category in sorted(all_categories):\n",
    "    column_name = category\n",
    "    items_preproccesed[column_name] = item_features_df['feat'].apply(lambda x: 1 if category in x else 0)\n",
    "items_preproccesed.drop(columns=[14, 23, 27, 21, 0, 30, 22, 24, 29], inplace=True)\n",
    "items_preproccesed.rename(columns={'video_id':'itemId'}, inplace=True)\n",
    "items_preproccesed.set_index('itemId', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f978c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContentBasedRecommender:\n",
    "    def __init__(self, item_features_df, params=None):\n",
    "        self.item_features_df = item_features_df\n",
    "        self.model = None\n",
    "        self.user_profiles = {}\n",
    "        \n",
    "        # Default XGBoost parameters\n",
    "        self.params = {\n",
    "            'objective': 'binary:logistic',\n",
    "            'eval_metric': 'logloss',\n",
    "            'eta': 0.1,\n",
    "            'max_depth': 6,\n",
    "            'subsample': 0.8,\n",
    "            'colsample_bytree': 0.8,\n",
    "            'min_child_weight': 1\n",
    "        }\n",
    "        \n",
    "        if params:\n",
    "            self.params.update(params)\n",
    "            \n",
    "    def fit(self, interactions_df, feature_cols=None):\n",
    "        \"\"\"Train an XGBoost model for content-based recommendations.\"\"\"\n",
    "        print(\"Preparing training data...\")\n",
    "        train_data = self.prepare_features(interactions_df)\n",
    "        \n",
    "        if feature_cols is None:\n",
    "            feature_cols = train_data.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "            feature_cols = [col for col in feature_cols if col not in ['userId', 'itemId', 'watch_ratio']]\n",
    "        \n",
    "        print(f\"Using features: {feature_cols}\")\n",
    "        \n",
    "        print(\"Training XGBoost model...\")\n",
    "        X = train_data[feature_cols].values\n",
    "        y = train_data['rating'].values\n",
    "        \n",
    "        # Create user-specific indices to enable personalized training\n",
    "        train_data['user_idx'] = train_data['userId'].astype('category').cat.codes\n",
    "        \n",
    "        # Create DMatrix for XGBoost\n",
    "        dtrain = xgb.DMatrix(X, label=y)\n",
    "        dtrain.set_group(train_data.groupby('user_idx').size().values)\n",
    "        \n",
    "        # Train the model\n",
    "        self.model = xgb.train(self.params, dtrain, num_boost_round=10)\n",
    "        \n",
    "        print(\"Creating user profiles...\")\n",
    "        # Create user profiles (average features of items each user has interacted with)\n",
    "        for user_id, group in train_data.groupby('userId'):\n",
    "            self.user_profiles[user_id] = group[feature_cols].mean().values\n",
    "            \n",
    "        return self\n",
    "    \"\"\"\n",
    "    def recommend(self, user_id, n=10, filter_viewed=True):\n",
    "        if user_id not in self.user_profiles:\n",
    "            print(f\"User {user_id} not found in training data\")\n",
    "            return []\n",
    "        \n",
    "        # Get all items\n",
    "        items = self.item_features_df.copy()\n",
    "        \n",
    "        # Get feature columns\n",
    "        feature_cols = [col for col in items.columns \n",
    "                       if col not in ['userId', 'itemId'] and items[col].dtype in ['int64', 'float64']]\n",
    "        \n",
    "        # Add user profile features to each item\n",
    "        user_profile = np.tile(self.user_profiles[user_id], (len(items), 1))\n",
    "        item_features = items[feature_cols].values\n",
    "        \n",
    "        # Combine user profile with item features\n",
    "        features = np.hstack([user_profile, item_features])\n",
    "        \n",
    "        # Make predictions\n",
    "        dtest = xgb.DMatrix(features)\n",
    "        items['score'] = self.model.predict(dtest)\n",
    "        \n",
    "        # Filter out items the user has already interacted with\n",
    "        if filter_viewed:\n",
    "            viewed_items = interactions_df[interactions_df['user_id'] == user_id]['click_history']\n",
    "            viewed_items = [item for sublist in viewed_items for item in sublist]  # Flatten list\n",
    "            items = items[~items['itemId'].isin(viewed_items)]\n",
    "        \n",
    "        # Sort by score and return top N\n",
    "        top_items = items.sort_values('score', ascending=False).head(n)\n",
    "        return top_items[['itemId', 'score']]\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1c8900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train the recommender\n",
    "recommender = ContentBasedRecommender(item_features_df)\n",
    "recommender.fit(train_data, feature_cols=items_preproccesed.columns.tolist())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
